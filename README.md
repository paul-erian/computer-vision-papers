# Computer Vision Papers

A personal collection of awesome papers on deep learning for computer vision and applied ML.

- [Foundational Backbones](#foundational-backbones)
- [Self Supervised Learning](#self-supervised-learning)
- [Multi-Modal](#multi-modal)
- [Generic Object Detection](#generic-object-detection)
- [Generic Object Segmentation](#generic-object-segmentation)
- [Applied ML & MLOps](#applied-ml--mlops)

## Papers

### Foundational Backbones

| Year | Name | Paper |
|------|------|-------|
| 2022 | ConvNeXt | [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) |
| 2020 | ViT | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) |
| 2017 | MobileNets | [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861) |
| 2015 | ResNet | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) |
| 2015 | InceptionNet | [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) |
| 2014 | VGG | [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) |
| 2012 | AlexNet | [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) |
| 1998 | LeNet | [LeNet-5: Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/lenet/) |

### Self Supervised Learning
| Year | Name | Paper |
|------|------|-------|
| 2023 | DINOv2 | [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193) |
| 2021 | MAE | [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) |

### Multi-Modal
| Year | Name | Paper |
|------|------|-------|
| 2023 | BLIP-2 | [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597) |
| 2021 | CLIP | [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) |

### Generic Object Detection
| Year | Name | Paper |
|------|------|-------|
| 2020 | DETR | [DETR: End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) |
| 2017 | FPN | [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144) |
| 2016 | SSD | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) |
| 2016 | YOLO | [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) |
| 2015 | Faster R-CNN | [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) |

### Generic Object Segmentation
| Year | Name | Paper |
|------|------|-------|
| 2023 | SAM | [Segment Anything Model](https://arxiv.org/abs/2304.02643) |
| 2019 | SOLO | [SOLO: Segmenting Objects by Locations](https://arxiv.org/abs/1912.04488) |
| 2017 | Mask R-CNN | [Mask R-CNN](https://arxiv.org/abs/1703.06870) |
| 2016 | DeepLab | [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915) |
| 2015 | U-Net | [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) |
| 2015 | FCN | [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038) |

### Applied ML & MLOps 
| Year | Paper |
|------|-------|
| 2022 |  [Machine Learning Operations (MLOps): Overview, Definition, and Architecture](https://arxiv.org/pdf/2205.02302) |
| 2020 | [Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology](https://arxiv.org/pdf/2003.05155) |
| 2019 | [Software Engineering for Machine Learning: A Case Study](https://www.microsoft.com/en-us/research/wp-content/uploads/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf)
| 2015 | [Hidden Technical Debt in Machine Learning Systems](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf) |
